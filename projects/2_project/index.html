<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> üß† üîê 2. Trial Decoding | üß†üè∑Ô∏è Selection of experience for memory by hippocampal sharp wave ripples </title> <meta name="author" content="Wannan Yang"> <meta name="description" content="Demo codes to decode event identity with 4 different methods."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/RippleTagging/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/RippleTagging/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/RippleTagging/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/RippleTagging/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A7%A0%F0%9F%8F%B7%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/RippleTagging/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://winnieyangwannan.github.io/RippleTagging/projects/2_project/"> <script src="/RippleTagging/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> <link defer rel="stylesheet" href="/RippleTagging/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/RippleTagging//"> üß†üè∑Ô∏è Selection of experience for memory by hippocampal sharp wave ripples </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/RippleTagging/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/RippleTagging/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/RippleTagging/Paper/">Paper </a> </li> <li class="nav-item "> <a class="nav-link" href="/RippleTagging/Codes%20and%20Demos/">Codes and Demos </a> </li> <li class="nav-item "> <a class="nav-link" href="/RippleTagging/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/RippleTagging/teaching/">teaching </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">üß† üîê 2. Trial Decoding</h1> <p class="post-description">Demo codes to decode event identity with 4 different methods.</p> </header> <article> <p>The companion notebook will walk you through the steps of visualizing data with UMAP!</p> <p>üîó Follow the demo code in Colab Notebook <a href="https://colab.research.google.com/drive/1D3BdR_TwraXgx7FEAUYx9MZkX5QEWjb1?usp=drive_link" rel="external nofollow noopener" target="_blank">here</a>! You will learn how to decode trial identity from population activity using four different methods!</p> <hr> <h1 id="part-1-supervised-dimensionality-reduction">Part 1: Supervised dimensionality reduction</h1> <p>In order to better visualize the trial-by-trial representation drift and check if the progression of population representation aligned with event sequences, we took advantage of the <a href="https://umap-learn.readthedocs.io/en/latest/supervised.html" rel="external nofollow noopener" target="_blank">supervised dimensionality reduction feature of the UMAP</a>.</p> <p>We plotted the result of supervised dimensionality reduction with UMAP and first colored it with linearized position (Fig. 1) and then colored it with trial block number (Fig. 2).</p> <div class="l-page"> <iframe src="/RippleTagging/assets/html/demo/umap_supervised_pos.html" frameborder="0" scrolling="no" height="500px" width="1000px" style="border: 1px dashed grey;"></iframe> </div> <div class="caption"> Fig 1. An <mark>interactive</mark> plot showing the supervised UMAP embedding of the neural data when a mouse was running on the figure-8 maze. (Left) UMAP embedding of population activity. Each point corresponds to the low-dimensional representation of one binned spiking data. (Right) running trajectory of a mouse on the figure-8 maze. Both the neural manifold and the running trajectory were colored by the animal's linearized position. </div> <blockquote class="block-tip"> <h5 id="tip">TIP!</h5> <p>This is an interactive plot! You can rotate the manifold and examine the manifold from different angles!! This figure might take a few seconds to render! Try to rotate the interactive plot such that the manifolds for the early trials (blue ones) are at the bottom of the plot and the red manifolds are at the top.</p> </blockquote> <div class="l-page"> <iframe src="/RippleTagging/assets/html/demo/umap_supervised_trial.html" frameborder="0" scrolling="no" height="500px" width="1000px" style="border: 1px dashed grey;"></iframe> </div> <div class="caption"> Fig 2. Similar to the previous plot, this <mark>interactive</mark> plot shows the supervised UMAP embedding of the neural data when a mouse was running on the figure-8 maze.Both the neural manifold and the running trajectory were colored by trial block number. </div> <hr> <h1 id="part-2-trial-decoding">Part 2: Trial decoding</h1> <p>To quantify the trial sequence information present in the state space, we tested if trial block membership can be accurately decoded from the population activity.</p> <p>Here we give a very high level overview of the main steps of UMAP.</p> <p>Successive five trials composed a trial block, and a specific label was assigned to each trial block. Decoding was performed using a k-nearest neighbor (kNN) decoder.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/RippleTagging/assets/img/demo/2/UMAP_explain-480.webp 480w,/RippleTagging/assets/img/demo/2/UMAP_explain-800.webp 800w,/RippleTagging/assets/img/demo/2/UMAP_explain-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/RippleTagging/assets/img/demo/2/UMAP_explain.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> </div> </div> <div class="caption"> Fig 3. Similar to the previous plot, this <mark>interactive</mark> plot shows the supervised UMAP embedding of the neural data when a mouse was running on the figure-8 maze.Both the neural manifold and the running trajectory were colored by trial block number. </div> <h1 id="part-3-cross-validation-with-leaving-one-trial-out">Part 3: Cross-validation with ‚Äòleaving one trial out‚Äô</h1> <p>For cross-validation, we used the standard 10-fold cross-validation as well as the more targeted ‚Äòleaving one trial out‚Äô method. We want to highlight the ‚Äòleaving one trial out‚Äô cross-validation procedure here because we believe it is the most convincing evidence that the population activity pattern varied systematically across trials. This is because as long as the different trial patterns are sufficiently differentiable, they can be decoded. We need a method from which we can conclude beyond decodadability, but can demonstrate that the variation is actually structured!</p> <p>‚ÄòLeaving one trial out‚Äô is such a method. To elaborate, ‚Äòleaving one trial out‚Äô is expected to yield high decoding accuracy only if the state space of the data changed in a structured way, evolving along one axis according to the sequence of trial events. This is because this validation method makes sure that the training set does not contain any data that shar the trial block membership with the test set, the test data could be decoded only to the next closest trial block (but not the same trial block) in the state space (Fig. 3 C). Note that the diagonal (red dashed line) of the confusion matrix had 0 decoding probability because the training and test data did not share any data from the same trial block. Since the neural embedding was structured according to the progression of trial events, the test data were correctly decoded to their nearest neighbors.</p> <div class="row mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/RippleTagging/assets/img/demo/2/validation_methods_github-480.webp 480w,/RippleTagging/assets/img/demo/2/validation_methods_github-800.webp 800w,/RippleTagging/assets/img/demo/2/validation_methods_github-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/RippleTagging/assets/img/demo/2/validation_methods_github.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> Fig 4. Leave entire trial block out validation results from four different decoding methods. </div> <details><summary>Click here to read the full figure legend.</summary> <p>(A) Illustration of the hold entire trial block out validation method. Top, neural manifold from all the data in one example session. To give an example of the cross-validation procedure, data from one trial block (trial block 4; blue) was highlighted. Middle, the highlighted trial block in A was held out as test data. After removing the test data, a kNN decoder was trained only using training data (grey). Bottom, the test data was then embedded with the learned manifold (generated from training data), and the kNN decoder was used for trial block membership decoding. Test data was decoded to the trial block label of its nearest neighbor (trial block 3) on the training data manifold. Training data was gray and test data was colored by the identity of the decoded trial block.</p> <p>(B) Illustration of the 10-fold cross-validation method. Top, neural manifold generated from all the data in one example session. 10% of the data were highlighted (colored by their true trial block identity). The highlighted data was held out as test data. Middle, after removing the t est data, a kNN decoder was trained only using training data (grey). Bottom, embedding the test data with the training manifold and us ing the kNN decoder for trial block identity decoding. Training data was gray and test data was colored by the identity of the decoded trial block (trial block 3).</p> <p>(C) Confusion matrix obtained using hold entire trial block out validation. Note that the diagonal (red dashed line) of the confusion matrix had 0 decoding probability because the training and test data did not share any data from the same trial block. Since the neural embedding was structured according to the progression of trial events, the test data were correctly decoded to their nearest neighbors.</p> <p>(D) Confusion matrix from UMAP trial block decoding using hold entire trial block out validation.</p> </details> <hr> <h1 id="part-4-decoding-from-the-original-high-dimensional-space-and-pca-space">Part 4: Decoding from the original high-dimensional space and PCA space</h1> <p>Can we trust the decoding result based on uMAP embedding? We know that dimensionality reduction can potentially distort the relationship between data points in the original dimensional space. In order to make sure our conclusion is not the result of potential distortion during the dimensionality reduction process, we repeated the KNN decoding and leave one out cross validation procedure from the original high-dimensional space (Fig. 4 B and C) as well as PCA space (Fig. 4A).</p> <div class="row mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/RippleTagging/assets/img/demo/2/validation_methods_other_github-480.webp 480w,/RippleTagging/assets/img/demo/2/validation_methods_other_github-800.webp 800w,/RippleTagging/assets/img/demo/2/validation_methods_other_github-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/RippleTagging/assets/img/demo/2/validation_methods_other_github.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> Fig 5. Confusion matrix of trial block decoding results. </div> <p>As we can see, all those methods yield consistent conclusion with UMAP.</p> <hr> <h1 id="part-5-can-we-use-umap-for-trial-decoding">Part 5: Can we use UMAP for trial decoding?</h1> <p>Does UMAP introduce any distortion that could affect accuracy of the trial decoding results? In oder to demonstrate that we could use UMAP for trial decoding, we need to demonstrate that the trial block membership is consistent between the high and low-dimensional space.</p> <div class="row mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/RippleTagging/assets/img/demo/2/decoding_high_low-480.webp 480w,/RippleTagging/assets/img/demo/2/decoding_high_low-800.webp 800w,/RippleTagging/assets/img/demo/2/decoding_high_low-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/RippleTagging/assets/img/demo/2/decoding_high_low.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> Fig 6. Consistent trial block membership between the low-dimensional and the original high-dimensional space. </div> <details><summary>Click here to read the full figure legend.</summary> <p>(A) Diagram explaining the main steps of trial block decoding from the original high -dimensional space. Step 1: by default, a weighted nearest neighbor (kNN) graph, which connects each datapoint to its nearest neighbors, was constructed and used to generate the initial topological representation of the training dataset (dots in three different colors). Step 2: the trial block membership of the test dat a (purple triangle) was decoded by taking the mode of its k nearest neighbors. For example, the example test data point (purple triangle) was decoded to be trial block 3 because all of its three nearest neighbors in the original high-dimensional space belong to trial block 3 (purple).</p> <p>(B) Diagram explaining the main steps of trial block decoding from the low -dimensional space generated by UMAP. Step 1 was the same as in panel (A). Step 2: optimize the low -dimensional representation to preserve the topological representation as much as possible to that in the original high-dimensional space. Step 3: The trial block membership of the test data (purple triangle) was decoded by taking the mode of its nearest neighbors in the low -dimensional embedding. For example, the example test data point (purple triangle) was decoded to be trial block 3 because all its three nearest neighbors in the low -dimensional space belong to trial 3 block (purple).</p> </details> <hr> <h1 id="part-6-can-electrode-drift-explain-what-we-see">Part 6: Can electrode drift explain what we see?</h1> <div class="row mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/RippleTagging/assets/img/demo/2/stationary-480.webp 480w,/RippleTagging/assets/img/demo/2/stationary-800.webp 800w,/RippleTagging/assets/img/demo/2/stationary-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/RippleTagging/assets/img/demo/2/stationary.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> Fig 7. Assessment of single-unit stability over time. </div> <details><summary>Click here to read the full figure legend.</summary> <p>(A) Waveform amplitude over time (on-maze duration) for all the cells in an example session. Spikes of individual neurons are color-coded by amplitude. The spike amplitude value was extracted from Amplitudes.npy, which was generated by Kilosort/Phy. It is a measure of each spike‚Äôs amplitude in the template space.</p> <p>(B) Scatter plot of waveform amplitude in the first quarter of on- maze recording compared to the last quarter , for all the isolated units from the entire figure- 8 maze dataset (Pearson correlation coefficient, N = 4469 cells from 6 animals).</p> <p>(C) Single-unit waveform centroid displacement across time, from a representative session , plotted in 3-D space. Centroid was computed by taking the spatial average across electrode positions weighted by the squared mean waveform amplitude at each electrode (see Methods for details). Waveform centroid for each single unit during the first quarter (blue circles) and last quarter of recording (red triangles) were connected by red lines (note: most of them were very short and not visible). The large semi-transparent orange and blue circles indicate the positions of the dual-sided probe‚Äôs 128 electrode sites (blue, and orange, front and back sides of the dual-sided probe, respectively).</p> <p>(D) Cumulative distribution of unit centroid displacement between the first and the last quarter of maze recording for all the cells in the dataset (median = 2.81- um, Q1 = 1.37- um, Q3 = 5.46- um; N= 4469 cells from 6 animals).</p> </details> <hr> <h1 id="how-to-cite-us-">How to cite us ?</h1> <p>Enjoyed reading this post and found our demo code useful? It can be cited as follows:</p> <p>Wannan Yang, Chen Sun, Roman Husz√°r, Thomas Hainmueller, Kirill Kiselev, Gy√∂rgy Buzs√°ki. ‚ÄúSelection of experience for memory by hippocampal sharp wave ripple.‚Äù <em>Science</em> (2024).</p> </article> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2024 Wannan Yang. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/RippleTagging/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/RippleTagging/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/RippleTagging/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/RippleTagging/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/RippleTagging/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/RippleTagging/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/RippleTagging/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/RippleTagging/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>